{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity analysis\n",
    "In this stage, you are asked to perform similarity analysis on the review sentences. The analysis involves segmenting review body into multiple sentences; encoding each sentence as vector so that the distance between pair of sentences can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.2-bin-hadoop2.7\"\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Stage three\") \\\n",
    "    .getOrCreate()\n",
    "music_data = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Music_v1_00.tsv.gz'\n",
    "musics= spark.read.csv(music_data,header=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from pyspark.sql.functions import *\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def sent_token(s):\n",
    "    sent_list = sent_tokenize(str(s))\n",
    "    return sent_list\n",
    "seg = udf(lambda s: sent_token(s), ArrayType(StringType()))\n",
    "musics = musics.withColumn('sentences',seg(musics.review_body).alias('seg'))\n",
    "musics.show()\n",
    "musics_review = musics.select(musics.review_id, musics.star_rating, explode(musics.sentences).alias(\"sentence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given product, consider all reviews with star rating 4 and above as positive reviews; and all reviews with star rating 2 and below as negative reviews. You are asked to pick a product from the top 10 products you find in stage One. The positive class is constructed by\n",
    "\n",
    "• extracting all reviews with rate 4 and above\n",
    "• for each review, extracting the review body part and segment it into multiple sentences.\n",
    "\n",
    "The negative class is constructed in similar manner except that we extract all reviews with rate 2 and below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musics_review = musics_review.filter(length(musics_review.sentence)>1)\n",
    "musics_review.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicsP=musics_review.filter(musics.star_rating>=4)\n",
    "musicsN=musics_review.filter(musics.star_rating<=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicsP= musicsP.withColumn(\"id\", monotonically_increasing_id())\n",
    "musicsN = musicsN.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-80c54e70a2e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreview_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev_text_partition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodule_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder/2\"\u001b[0m \u001b[0;31m#@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "def review_embed(rev_text_partition):\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "    #2 for cpu\n",
    "    embed = hub.Module(module_url)\n",
    "    # mapPartition would supply element inside a partition using generator stype\n",
    "    # this does not fit tensorflow stype\n",
    "    rev_text_list = []\n",
    "    for text in  rev_text_partition:\n",
    "        for i in text:\n",
    "            rev_text_list.append(i)\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed(rev_text_list))\n",
    "    return message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_text_P = musicsP.select('sentence')\n",
    "rev_clean_text_rdd_P = rev_text_P.rdd.filter(lambda data: data is not None).cache()\n",
    "rev_clean_text_rdd_P.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_text_N = musicsN.select('sentence')\n",
    "rev_clean_text_rdd_N = rev_text_N.rdd.filter(lambda data: data is not None).cache()\n",
    "rev_clean_text_rdd_N.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_embedding_P = rev_clean_text_rdd_P.mapPartitions(review_embed).cache()\n",
    "review_embedding_P.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_embedding_N = rev_clean_text_rdd_N.mapPartitions(review_embed).cache()\n",
    "review_embedding_N.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_P = review_embedding_P.collect()\n",
    "list_N = review_embedding_N.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find out if sentences in the same category are closely related with each other. The closeness is measured by average distance between points in the class. In our case, point refers to the sentence encoding and pair-wise distance is measured by Cosine distance. Cosine distance is computed as “1 − CosineSimilarity”. It has a value between 0 and 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(rew1,rew2):\n",
    "    mul=np.dot(rew1,rew2)\n",
    "    norm=np.linalg.norm(rew1)*np.linalg.norm(rew2)\n",
    "    return mul/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sim(List):\n",
    "    for i in range(0,len(List)):\n",
    "        sumOfsim = 0\n",
    "        for j in range(0,len(List)):\n",
    "            sumOfsim = sumOfsim + (1 - calculate_similarity(List[i],List[j]))        \n",
    "        if (i == 0 ):\n",
    "            min_sum = sumOfsim\n",
    "            index = 0\n",
    "        else:\n",
    "            if (sumOfsim < min_sum):\n",
    "                min_sum = sumOfsim\n",
    "                index = i\n",
    "    return min_sum , index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_P,index_P = min_sim(list_P)\n",
    "min_P,index_N = min_sim(list_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TenNeighbors(List , index):\n",
    "    list = []\n",
    "    for i in range(len(List)):\n",
    "        sim = (1-calculate_similarity(List[i],List[index]))\n",
    "        list.append(sim)\n",
    "    indexes = np.argsort(list)\n",
    "    return indexes[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_P = TenNeighbors(list_P , index_P)\n",
    "indexes_N = TenNeighbors(list_N , index_N)\n",
    "print(indexes_P,indexes_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicsP.select('review_id','sentence').filter(musicsP.id.isin(indexes_P)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicsN.select('review_id','sentence').filter(musicsN.id.isin(indexes_P)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out the class center and its 10 closest neighbours for positive and negative class respectively. We define class center as the point that has the smallest average distance to other points in the class. Again in this case point refers to the sentence encoding and pair-wise distance are measured by Cosine distance.\n",
    "\n",
    "The result should show the text of the center sentence, the review id it belongs to and its 10 closest neighbouring sentences text and their respective review id."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
